{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os módulos\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd      \n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "import Functions as fn\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain = pd.read_csv('train.csv', names=['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], sep=',', header=0, dtype={'Age': np.float64})\n",
    "dstest  = pd.read_csv('test.csv',  names=['PassengerId',             'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], sep=',', header=0, dtype={'Age': np.float64})\n",
    "dsfull = [dstrain, dstest]\n",
    "\n",
    "print (dstrain.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Dataframes\n",
    "\n",
    "dstraincopy = dstrain.copy()\n",
    "dstestcopy  = dstest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem valores nulos e constituição das variáveis.\n",
    "\n",
    "#Pclass\n",
    "print('#Pclass')\n",
    "print (dstrain[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Sex\n",
    "print('#Sex')\n",
    "print (dstrain[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#SibSp and Parch\n",
    "print('#SibSp and #Parch')\n",
    "for dataset in dsfull:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    \n",
    "print('Size')\n",
    "print (dstrain[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())\n",
    "\n",
    "for dataset in dsfull:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "print('Alone')\n",
    "print (dstrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Embarked\n",
    "print('#Embarked')\n",
    "for dataset in dsfull:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    \n",
    "print (dstrain[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Fare\n",
    "print('#Fare')\n",
    "for dataset in dsfull:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dstrain['Fare'].median())\n",
    "    \n",
    "dstrain['CategoricalFare'] = pd.qcut(dstrain['Fare'], 4)\n",
    "print (dstrain[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Age\n",
    "print('#Age')\n",
    "for dataset in dsfull:\n",
    "    age_avg \t   = dataset['Age'].mean()\n",
    "    age_std \t   = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    \n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "dstrain['CategoricalAge'] = pd.cut(dstrain['Age'], 5)\n",
    "print (dstrain[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Name\n",
    "print('#Name')\n",
    "for dataset in dsfull:\n",
    "    dataset['Title'] = dataset['Name'].apply(fn.getTitle)\n",
    "\n",
    "print(pd.crosstab(dstrain['Title'], dstrain['Sex']))\n",
    "\n",
    "for dataset in dsfull:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "print (dstrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar\n",
    "\n",
    "for dataset in dsfull:\n",
    "    # Mapping Sex\n",
    "    fn.setSex(dataset, 'Sex')\n",
    "    \n",
    "    # Mapping titles\n",
    "    fn.setTitle(dataset, 'Title')\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    fn.setEmbarked(dataset, 'Embarked')\n",
    "    \n",
    "    # Mapping Fare\n",
    "    fn.setFare(dataset, 'Fare')\n",
    "    \n",
    "    # Mapping Age\n",
    "    fn.setAge(dataset, 'Age')\n",
    "    \n",
    "# Feature Selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'FamilySize']\n",
    "dstrain = dstrain.drop(drop_elements, axis = 1)\n",
    "dstrain = dstrain.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "dstest  = dstest.drop(drop_elements, axis = 1)\n",
    "\n",
    "print (dstrain.head(10))\n",
    "\n",
    "dsresult = dstrain.copy()\n",
    "dstrain = dstrain.values\n",
    "dstest  = dstest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a correlação em tabela\n",
    "\n",
    "# Coeficiente de correlação: \n",
    "# +1  = forte correlação positiva\n",
    "# 0   = não há correlação\n",
    "# -1  = forte correlação negativa\n",
    "fn.corr(dsresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "survived = 'survived'\n",
    "not_survived = 'not survived'\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n",
    "\n",
    "women = dsresult[dsresult['Sex']==0]\n",
    "men = dsresult[dsresult['Sex']==1]\n",
    "\n",
    "ax = sns.distplot(women[women['Survived']==1].Age, bins=18, label = survived, ax = axes[0], kde =False)\n",
    "ax = sns.distplot(women[women['Survived']==0].Age, bins=40, label = not_survived, ax = axes[0], kde =False)\n",
    "ax.legend()\n",
    "ax.set_title('Female')\n",
    "\n",
    "ax = sns.distplot(men[men['Survived']==1].Age, bins=18, label = survived, ax = axes[1], kde = False)\n",
    "ax = sns.distplot(men[men['Survived']==0].Age, bins=40, label = not_survived, ax = axes[1], kde = False)\n",
    "ax.legend()\n",
    "ax = ax.set_title('Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica a relação entre a variável preditora x as independentes\n",
    "\n",
    "fn.plot(dsresult, 'Survived', 'Pclass')\n",
    "#fn.plot(dsresult, 'Survived', 'Sex')\n",
    "#fn.plot(dsresult, 'Survived', 'Age')\n",
    "#fn.plot(dsresult, 'Survived', 'Fare')\n",
    "#fn.plot(dsresult, 'Survived', 'Embarked')\n",
    "#fn.plot(dsresult, 'Survived', 'IsAlone')\n",
    "#fn.plot(dsresult, 'Survived', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = dstrain[0::, 1::]\n",
    "y = dstrain[0::, 0]\n",
    "\n",
    "accuracy_score(X, y, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos classificadores\n",
    "\n",
    "# Suprime erros\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação dos classificadores\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression(),\n",
    "    XGBClassifier()]\n",
    "\n",
    "splits = 12\n",
    "cols = [\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=cols)\n",
    "\n",
    "tx = dstrain[0::, 1::]\n",
    "ty = dstrain[0::, 0]\n",
    "\n",
    "#kfold = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n",
    "kfold = KFold(n_splits=splits, random_state=42, shuffle=True)\n",
    "#shuffle = StratifiedShuffleSplit(n_splits=splits, test_size=0.6, random_state=0)\n",
    "\n",
    "#shufflesplit = StratifiedShuffleSplit(n_splits=2, test_size=0.5, random_state=0)\n",
    "#shufflesplit.get_n_splits(tx, ty)\n",
    "#print(shufflesplit)       \n",
    "\n",
    "#print(\"KFold\")\n",
    "#for train_index, test_index in kfold.split(tx, ty):\n",
    "#    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "X = dstrain[0::, 1::]\n",
    "y = dstrain[0::, 0]\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += acc\n",
    "        else:\n",
    "            acc_dict[name] = acc\n",
    "\n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] = acc_dict[clf] / 10.0\n",
    "    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=cols)\n",
    "    log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação dos classificadores\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression(),\n",
    "    XGBClassifier()]\n",
    "\n",
    "splits = 12\n",
    "cols = [\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=cols)\n",
    "acc_dict = {}\n",
    "\n",
    "tx = dstrain[0::, 1::]\n",
    "ty = dstrain[0::, 0]\n",
    "\n",
    "kfold = KFold(n_splits=splits, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kfold.split(tx, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += acc\n",
    "        else:\n",
    "            acc_dict[name] = acc\n",
    "\n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] = acc_dict[clf] / 10.0\n",
    "    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=cols)\n",
    "    log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Classifier Accuracy\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log)\n",
    "\n",
    "log.groupby(['Classifier', 'Accuracy']).count().sort_values(by=['Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(dstrain[0::, 1::], dstrain[0::, 0])\n",
    "predictions = classifier.predict(dstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv to upload to Kaggle\n",
    "\n",
    "#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\n",
    "dssubmission = pd.DataFrame({'PassengerId': dstestcopy['PassengerId'], 'Survived': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dssubmission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dssubmission.groupby(['Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.plot(dssubmission, 'Survived', 'Survived')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
