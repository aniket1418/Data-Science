{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Brasil - Desafio Kaggle - Titanic\n",
    "\n",
    "#### Equipe:\n",
    "    * Ricardo Galiardi \n",
    "    * Wanderson Henrique dos Santos\n",
    "    * Neri Silvestre Filho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "#### Treino\n",
    "    Columns\n",
    "        * PassengerId: type should be integers\n",
    "        * Survived: Survived or Not\n",
    "        * Pclass: Class of Travel\n",
    "        * Name: Name of Passenger\n",
    "        * Sex: Gender\n",
    "        * Age\n",
    "        * SibSp: Number of Sibling/Spouse aboard\n",
    "        * Parch: Number of Parent/Child aboard\n",
    "        * Ticket\n",
    "        * Fare\n",
    "        * Cabin\n",
    "        * Embarked: The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown\n",
    "            \n",
    "#### Teste\n",
    "    Columns\n",
    "        * PassengerId\n",
    "        * Pclass\n",
    "        * Name\n",
    "        * Sex\n",
    "        * Age\n",
    "        * SibSp\n",
    "        * Parch\n",
    "        * Ticket\n",
    "        * Fare\n",
    "        * Cabin\n",
    "        * Embarked\n",
    "        \n",
    "#### Conversões\n",
    "    Columns\n",
    "        * Sex:      {'female': 0, 'male': 1}\n",
    "        * Age:      {\"Missing\": 0, \"Infant\": 1, \"Child\": 2, \"Teenager\": 3, \"Adult\": 4, \"Senior\": 5}\n",
    "        * Fare:     {\"Inferior\": 0, \"Basic\": 1, \"Superior\": 2, \"Executive\": 3}\n",
    "        * Title:    {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "        * Embarked: {'S': 0, 'C': 1, 'Q': 2}\n",
    "        \n",
    "#### Envio\n",
    "    Columns\n",
    "        * PassengerId: integer\n",
    "        * Survived: binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importando xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Notes\n",
    "    * survival\n",
    "        * 0 = No\n",
    "        * 1 = Yes\n",
    "    * pclass: A proxy for socio-economic status (SES)\n",
    "        * 1: 1st = Upper\n",
    "        * 2: 2nd = Middle\n",
    "        * 3: 3rd = Lower\n",
    "    * age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "    * sibsp: The dataset defines family relations in this way...\n",
    "        * Sibling = brother, sister, stepbrother, stepsister\n",
    "        * Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "    * parch: The dataset defines family relations in this way...\n",
    "        * Parent = mother, father\n",
    "        * Child = daughter, son, stepdaughter, stepson\n",
    "        * Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "    * embarked: \n",
    "        * C = Cherbourg\n",
    "        * Q = Queenstown\n",
    "        * S = Southampton  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install xgboost\n",
    "#!pip3 install --force-reinstall scikit-learn==0.20rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista os arquivos\n",
    "\n",
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os módulos\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd      \n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "import Functions as fn\n",
    "%matplotlib inline       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara os datasets\n",
    "\n",
    "dstrain = pd.read_csv('train.csv', names=['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], sep=',', header=0, dtype={'Age': np.float64})\n",
    "dstest  = pd.read_csv('test.csv',  names=['PassengerId',             'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], sep=',', header=0, dtype={'Age': np.float64})\n",
    "dsfull = [dstrain, dstest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Dataframes\n",
    "\n",
    "dstraincopy = dstrain.copy()\n",
    "dstestcopy  = dstest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os primeiros registros\n",
    "\n",
    "dstrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se existem valores nulos e constituição das variáveis.\n",
    "\n",
    "#Pclass\n",
    "print('#Pclass')\n",
    "print (dstrain[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Sex\n",
    "print('#Sex')\n",
    "print (dstrain[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#SibSp and Parch\n",
    "print('#SibSp and #Parch')\n",
    "for dataset in dsfull:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    \n",
    "print('Size')\n",
    "print (dstrain[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())\n",
    "\n",
    "for dataset in dsfull:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "print('Alone')\n",
    "print (dstrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Embarked\n",
    "print('#Embarked')\n",
    "for dataset in dsfull:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    \n",
    "print (dstrain[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Fare\n",
    "print('#Fare')\n",
    "for dataset in dsfull:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dstrain['Fare'].median())\n",
    "    \n",
    "dstrain['CategoricalFare'] = pd.qcut(dstrain['Fare'], 4)\n",
    "print (dstrain[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Age\n",
    "print('#Age')\n",
    "for dataset in dsfull:\n",
    "    age_avg \t   = dataset['Age'].mean()\n",
    "    age_std \t   = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    \n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "dstrain['CategoricalAge'] = pd.cut(dstrain['Age'], 5)\n",
    "print (dstrain[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())\n",
    "print('\\n')\n",
    "\n",
    "#Name\n",
    "print('#Name')\n",
    "for dataset in dsfull:\n",
    "    dataset['Title'] = dataset['Name'].apply(fn.getTitle)\n",
    "\n",
    "print(pd.crosstab(dstrain['Title'], dstrain['Sex']))\n",
    "\n",
    "for dataset in dsfull:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "print (dstrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar\n",
    "\n",
    "for dataset in dsfull:\n",
    "    # Mapping Sex\n",
    "    fn.setSex(dataset, 'Sex')\n",
    "    \n",
    "    # Mapping titles\n",
    "    fn.setTitle(dataset, 'Title')\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    fn.setEmbarked(dataset, 'Embarked')\n",
    "    \n",
    "    # Mapping Fare\n",
    "    fn.setFare(dataset, 'Fare')\n",
    "    \n",
    "    # Mapping Age\n",
    "    fn.setAge(dataset, 'Age')\n",
    "\n",
    "# Copy Normalization\n",
    "dscopy = dstrain.copy()\n",
    "\n",
    "# Feature Selection\n",
    "#drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'FamilySize']\n",
    "drop_elements = ['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'FamilySize']\n",
    "dstrain = dstrain.drop(drop_elements, axis = 1)\n",
    "dstrain = dstrain.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "dstest  = dstest.drop(drop_elements, axis = 1)\n",
    "\n",
    "print (dstrain.head(10))\n",
    "\n",
    "dsresult = dstrain.copy()\n",
    "dstrain = dstrain.values\n",
    "dstest  = dstest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a correlação em tabela\n",
    "\n",
    "# Coeficiente de correlação: \n",
    "# +1  = forte correlação positiva\n",
    "# 0   = não há correlação\n",
    "# -1  = forte correlação negativa\n",
    "fn.corr(dsresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploração dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica a relação entre a variável preditora x as independentes\n",
    "\n",
    "#fn.plot(dsresult, 'Survived', 'Pclass')\n",
    "#fn.plot(dsresult, 'Survived', 'Sex')\n",
    "#fn.plot(dsresult, 'Survived', 'Age')\n",
    "#fn.plot(dsresult, 'Survived', 'Fare')\n",
    "#fn.plot(dsresult, 'Survived', 'Embarked')\n",
    "fn.plot(dsresult, 'Survived', 'IsAlone')\n",
    "#fn.plot(dsresult, 'Survived', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação dos classificadores\n",
    "\n",
    "# Suprime erros\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação dos classificadores\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression(),\n",
    "    XGBClassifier()]\n",
    "\n",
    "splits = 12\n",
    "cols = [\"Classifier\", \"Accuracy\"]\n",
    "acc_dict = {}\n",
    "log = pd.DataFrame(columns=cols)\n",
    "X = dstrain[0::, 1::]\n",
    "y = dstrain[0::, 0]\n",
    "\n",
    "kfold = KFold(n_splits=splits, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += acc\n",
    "        else:\n",
    "            acc_dict[name] = acc\n",
    "\n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] = acc_dict[clf] / 10.0\n",
    "    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=cols)\n",
    "    log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Classifier Accuracy\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log)\n",
    "\n",
    "log.groupby(['Classifier', 'Accuracy']).count().sort_values(by=['Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(dstrain[0::, 1::], dstrain[0::, 0])\n",
    "predictions = classifier.predict(dstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsfull\n",
    "\n",
    "print(len(predictions))\n",
    "print(dsresult.rowid)\n",
    "print(pd.DataFrame(dsfull).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv to upload to Kaggle\n",
    "\n",
    "#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\n",
    "dssubmission = pd.DataFrame({'PassengerId': dstra['PassengerId'], 'Survived': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the first 5 rows\n",
    "dssubmission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dssubmission.groupby(['Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.plot(dssubmission, 'Survived', 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert DataFrame to a csv file that can be uploaded\n",
    "#This is saved in the same directory as your notebook\n",
    "filename = 'kaggle_titanic.csv'\n",
    "\n",
    "dssubmission.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
